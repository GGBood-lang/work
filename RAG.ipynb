{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "class chatdoc():\n",
    "    def __init__(self):\n",
    "        self.documents = None\n",
    "        self.template = [\n",
    "    (\"system\", \"你是一个处理文档的秘书，你从不说自己是一个大模型或AI助手，你会根据下面提供的上下文继续回答问题。\\n 上下文内容: \\n {context} \\n\"),\n",
    "    (\"human\", \"你好! \"),\n",
    "    (\"ai\", \"你好!\"),\n",
    "    (\"human\", \"{question}\")\n",
    "]\n",
    "        self.prompt = ChatPromptTemplate.from_messages(self.template)  \n",
    "    \n",
    "    def get_file(self):\n",
    "        loader = TextLoader(\"C:/Users/27504/Desktop/小说文本.txt\")\n",
    "        self.documents = loader.load()  \n",
    "    \n",
    "    def split(self):\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=20)\n",
    "        document = text_splitter.split_documents(self.documents)\n",
    "        self.documents=document \n",
    "        \n",
    "    def embedding(self):\n",
    "        openai_api_key = \"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\"  \n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "        db = Chroma.from_documents(documents=self.documents, embedding=embeddings)\n",
    "        return db\n",
    "    \n",
    "    def askAndFindFiles(self, question):\n",
    "        db = self.embeddingAndVectorDB() \n",
    "        retriever = db.as_retriever()  \n",
    "        llm = OpenAI(temperature=0)\n",
    "        compressor = LLMChainExtractor.from_llm(llm=llm)  \n",
    "        compressor_retriever = ContextualCompressionRetriever(\n",
    "        base_retriever=retriever,\n",
    "        base_compressor=compressor,)\n",
    "        return compressor_retriever.get_relevant_documents(query=question)\n",
    "    \n",
    "    def chatWithDoc(self, question):\n",
    "        _content = \"\"\n",
    "        context = self.askAndFindFiles(question)\n",
    "        for i in context:\n",
    "            _content += i.page_content\n",
    "\n",
    "        messages = self.prompt.format_messages(context=_content, question=question)\n",
    "        chat = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0)\n",
    "\n",
    "        return chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatdoc_instance = chatdoc()\n",
    "chatdoc_instance.get_file() \n",
    "chatdoc_instance.split()\n",
    "chatdoc_instance.embedding()\n",
    "response = chatdoc_instance.chatWithDoc(\"你好\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
